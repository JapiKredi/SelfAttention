{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyjcafio3P3FjewMKX25/W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JapiKredi/SelfAttention/blob/main/SelfAttention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GFYs76x1Swq",
        "outputId": "28b0b4da-8580-4c9a-c1ec-408df2a3cafc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8U-5sTFnggGv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def self_attention(input_sequence):\n",
        "    # Assume input_sequence is a 2D array where each row represents a token embedding\n",
        "\n",
        "    # Step 1: Calculate Query, Key, and Value matrices\n",
        "    Q = np.dot(input_sequence, W_q)  # Transform input embeddings to Query space\n",
        "    K = np.dot(input_sequence, W_k)  # Transform input embeddings to Key space\n",
        "    V = np.dot(input_sequence, W_v)  # Transform input embeddings to Value space\n",
        "\n",
        "    # Step 2: Calculate attention scores\n",
        "    scores = np.dot(Q, K.T) / np.sqrt(d_k)  # Scaled dot product attention\n",
        "    attention_weights = softmax(scores, axis=1)  # Apply softmax to obtain attention weights\n",
        "\n",
        "    # Step 3: Apply attention weights to Value vectors\n",
        "    attention_output = np.dot(attention_weights, V)  # Weighted sum of Value vectors\n",
        "\n",
        "    return attention_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example input sequence (3 tokens, each represented by a 4-dimensional vector)\n",
        "input_sequence = np.array([[1, 2, 3, 4],\n",
        "                           [2, 3, 4, 5],\n",
        "                           [3, 4, 5, 6]])\n"
      ],
      "metadata": {
        "id": "cJLZ-yrD0GXZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example weight matrices (learnable parameters)\n",
        "W_q = np.random.randn(4, 4)  # Query matrix\n",
        "W_k = np.random.randn(4, 4)  # Key matrix\n",
        "W_v = np.random.randn(4, 4)  # Value matrix"
      ],
      "metadata": {
        "id": "y1XZzbcw0Gxk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimension of Key and Query vectors\n",
        "d_k = W_q.shape[1]"
      ],
      "metadata": {
        "id": "Q1TxPNA80Mkp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Softmax function\n",
        "def softmax(x, axis=-1):\n",
        "    exp_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
        "    return exp_x / np.sum(exp_x, axis=axis, keepdims=True)"
      ],
      "metadata": {
        "id": "i18jQk320OZL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply self-attention\n",
        "output = self_attention(input_sequence)\n",
        "print(\"Output after self-attention:\")\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZWEXjcI0QBz",
        "outputId": "835f3eea-1aa1-4762-ec97-d23fb23b4a92"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output after self-attention:\n",
            "[[ 0.3080962   1.67488102 -7.23909351 10.31366241]\n",
            " [ 0.25418713  1.47595752 -7.71230413 11.67042054]\n",
            " [ 0.23733588  1.41377673 -7.86022335 12.09452473]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example using self-attention on a sentence\n"
      ],
      "metadata": {
        "id": "8xC2H3Dm0u4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import gensim.downloader as api"
      ],
      "metadata": {
        "id": "gDtlo7Q70Rkm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download GloVe embeddings (you can choose other pre-trained word embeddings as well)\n",
        "word_vectors = api.load(\"glove-wiki-gigaword-100\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSx1Z7UU0298",
        "outputId": "4fb1a630-1b2a-4437-bcc1-0b0ae76c9896"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_to_embeddings(sentence):\n",
        "    tokens = word_tokenize(sentence.lower())  # Tokenize the sentence\n",
        "    embeddings = []  # List to store word embeddings\n",
        "\n",
        "    for token in tokens:\n",
        "        if token in word_vectors:\n",
        "            embeddings.append(word_vectors[token])  # If word is in vocabulary, retrieve its embedding\n",
        "        else:\n",
        "            embeddings.append(np.zeros(word_vectors.vector_size))  # If word is out-of-vocabulary, use zero vector\n",
        "\n",
        "    return np.array(embeddings)"
      ],
      "metadata": {
        "id": "aW2i9Ngs07vw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def self_attention(input_sequence):\n",
        "    # Step 1: Calculate Query, Key, and Value matrices\n",
        "    Q = np.dot(input_sequence, W_q)  # Transform input embeddings to Query space\n",
        "    K = np.dot(input_sequence, W_k)  # Transform input embeddings to Key space\n",
        "    V = np.dot(input_sequence, W_v)  # Transform input embeddings to Value space\n",
        "\n",
        "    # Step 2: Calculate attention scores\n",
        "    scores = np.dot(Q, K.T) / np.sqrt(d_k)  # Scaled dot product attention\n",
        "    attention_weights = softmax(scores, axis=1)  # Apply softmax to obtain attention weights\n",
        "\n",
        "    # Step 3: Apply attention weights to Value vectors\n",
        "    attention_output = np.dot(attention_weights, V)  # Weighted sum of Value vectors\n",
        "\n",
        "    return attention_output"
      ],
      "metadata": {
        "id": "DfoaUgDt0-5B"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example weight matrices (learnable parameters)\n",
        "W_q = np.random.randn(word_vectors.vector_size, word_vectors.vector_size)  # Query matrix\n",
        "W_k = np.random.randn(word_vectors.vector_size, word_vectors.vector_size)  # Key matrix\n",
        "W_v = np.random.randn(word_vectors.vector_size, word_vectors.vector_size)  # Value matrix\n"
      ],
      "metadata": {
        "id": "H8EIo4a61DnQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimension of Key and Query vectors\n",
        "d_k = W_q.shape[1]"
      ],
      "metadata": {
        "id": "y7gBCQeN1GFk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Softmax function\n",
        "def softmax(x, axis=-1):\n",
        "    exp_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
        "    return exp_x / np.sum(exp_x, axis=axis, keepdims=True)"
      ],
      "metadata": {
        "id": "OeyCoXix1HyT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example sentence\n",
        "sentence = \"The quick brown fox jumps over the lazy dog.\""
      ],
      "metadata": {
        "id": "5B2yNZ5D1Jt6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert sentence to embeddings\n",
        "input_sequence = sentence_to_embeddings(sentence)"
      ],
      "metadata": {
        "id": "Qw2W1kkk1LIL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply self-attention\n",
        "output = self_attention(input_sequence)\n",
        "print(\"Output after self-attention:\")\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RFkGgcN1MhB",
        "outputId": "b3031be0-fb8a-40fd-a2e3-47394a98c62d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output after self-attention:\n",
            "[[ 10.5383473   -6.81568139   0.54388586  -8.26105457  -6.48654902\n",
            "    5.09520138   0.23069278   4.053301    -6.82900357   0.76474214\n",
            "    4.81274024   8.90122573  -9.28262123   4.38876221  -6.52846012\n",
            "   -1.24772382   8.36558712  -7.25393221  -0.30997645   3.46245024\n",
            "   -3.70074296  -2.01920212  12.53209955   6.29604624  -2.32583125\n",
            "    0.07558988  -3.33037453  -3.92278944  -3.20000669   8.59858666\n",
            "    1.1533959   -0.53729564   1.39028093   0.2033916   -7.94427866\n",
            "   -5.68902002   2.86276108  -5.41374109  -3.00488356   2.79683913\n",
            "   -6.78621478   0.84170686  -1.25506141   2.98129747  -7.46694073\n",
            "   -3.00169229   5.1258942   -2.54199045  -4.90104911   0.72238951\n",
            "   -0.83379572   2.29747668  -3.05484212  -1.53502808   1.1568491\n",
            "   -3.31387894  -5.25424941  -3.98067153  -2.2340476   -0.92174951\n",
            "   -0.35875352   0.66528344  -2.30993801  -5.6229472    7.50359115\n",
            "    7.57086726   4.82810394 -10.96710376   4.29291668   5.06484236\n",
            "    3.6850362   -6.11842411   7.56400839   5.29901244  -1.9808138\n",
            "    3.2527683    1.21343356  -1.70527137  -5.31421106   1.14584901\n",
            "    4.71850513  -1.87540785  -2.99690729 -10.48043318  -6.84088828\n",
            "   -4.62129564  -0.8102366    3.54735942   2.77005886  -2.89527653\n",
            "    0.56235537   5.66579595   7.3481624   -4.41751774  -9.02891486\n",
            "   -4.14008579  -5.74163471   0.86209123   1.44747442  -0.35400326]\n",
            " [ 10.53898949  -6.82132058   0.54086022  -8.26452243  -6.49020049\n",
            "    5.099061     0.23015325   4.05048372  -6.83051609   0.76352132\n",
            "    4.81234774   8.90869721  -9.28640928   4.39459508  -6.53435835\n",
            "   -1.24411558   8.36926098  -7.25607044  -0.31498853   3.46809291\n",
            "   -3.70786178  -2.01847451  12.531368     6.30529782  -2.32798977\n",
            "    0.08163005  -3.32780387  -3.92653566  -3.19472004   8.603096\n",
            "    1.15250087  -0.53860833   1.39664825   0.20216959  -7.94974146\n",
            "   -5.69868151   2.85547908  -5.41415205  -3.0095941    2.80072595\n",
            "   -6.78931952   0.84415622  -1.2562537    2.97998076  -7.469205\n",
            "   -3.00360364   5.12660278  -2.54310339  -4.89948468   0.7228033\n",
            "   -0.82595282   2.30012008  -3.0543508   -1.53419073   1.16002253\n",
            "   -3.31702528  -5.25566677  -3.98440421  -2.23644517  -0.92392654\n",
            "   -0.36744876   0.66227153  -2.31293207  -5.62405242   7.50278027\n",
            "    7.57519148   4.83401551 -10.97933924   4.29392887   5.06163043\n",
            "    3.68731727  -6.12541685   7.56602866   5.29726047  -1.98157172\n",
            "    3.25446048   1.21224865  -1.70632893  -5.32010436   1.1452445\n",
            "    4.7197576   -1.87895062  -2.99511067 -10.4840366   -6.84520389\n",
            "   -4.62210389  -0.80754523   3.55190762   2.76767357  -2.90210248\n",
            "    0.55991456   5.66479796   7.34904248  -4.41767333  -9.03010026\n",
            "   -4.14200844  -5.74545078   0.86201818   1.44790841  -0.35715119]\n",
            " [  4.42017571  -0.84559169 -10.237395    -5.81587213   0.25647981\n",
            "    1.12640959   8.1538393    3.00638136  -7.88473212   3.81855489\n",
            "    4.37599831  -8.26352889   1.37645391   2.22544474  -2.59741542\n",
            "    1.42315784  -0.62664224   0.40479007   3.64397243  12.29452636\n",
            "    7.59595928   3.63625479   8.77285327 -11.14793064  -5.52549971\n",
            "   -2.31103216  -4.73465849   4.24545764 -13.41292743   5.31466647\n",
            "    7.34168846   2.13728259  -9.51750058  -4.36479433   1.40634073\n",
            "   -6.48082705   5.46835754  -1.68231453  -3.52183171  12.60454609\n",
            "   -4.50494796  -8.29718374   1.62484609  14.96719814  -9.04955355\n",
            "    0.2240682   -0.13107875  -1.93529115  -8.50311732  -5.62798107\n",
            "  -10.66103219  -0.54600482  -4.95867655   5.69431744  -1.56409852\n",
            "    3.88538789  -5.70420184   1.05067126  11.27777588   2.63748675\n",
            "   -0.92213654   6.77446217   2.88475708  -6.25791037   0.45770408\n",
            "   -3.96071475  -7.03787414  -2.95703963   4.1119685   10.32664986\n",
            "    3.4483322    4.7376122    4.40114178   5.82708569   8.04774627\n",
            "   11.81321039   9.19829716  -4.02001253   0.67663323   1.466784\n",
            "   13.33304999   5.46360478  -3.81371557  -1.17017384   1.02276763\n",
            "   -8.65693713 -11.13877552   2.64971239  -6.85142432   0.51883\n",
            "   12.8939396    3.66034783   2.98231543   2.96625914  -4.17314366\n",
            "  -11.58903512   2.64353937   3.92049241   2.51857812   6.203539  ]\n",
            " [  4.42018172  -0.84559617 -10.23738454  -5.81587381   0.25647344\n",
            "    1.12641299   8.15383184   3.00638216  -7.88473152   3.81855175\n",
            "    4.37599808  -8.26351191   1.37644316   2.22544646  -2.5974185\n",
            "    1.42315489  -0.6266331    0.40478208   3.64396792  12.29451686\n",
            "    7.59594886   3.63624796   8.77285637 -11.1479134   -5.52549589\n",
            "   -2.31102965  -4.73465659   4.24544937 -13.41291652   5.31466823\n",
            "    7.3416827    2.13728012  -9.51749069  -4.36478924   1.40633163\n",
            "   -6.48082474   5.4683564   -1.68231908  -3.52183193  12.60453506\n",
            "   -4.50494914  -8.29717559   1.62484398  14.96718618  -9.04955256\n",
            "    0.22406435  -0.131073    -1.93529168  -8.50311406  -5.62797459\n",
            "  -10.66102235  -0.54600347  -4.95867452   5.69431037  -1.56409587\n",
            "    3.88538096  -5.70420076   1.05066604  11.27776186   2.63748326\n",
            "   -0.92213497   6.77445648   2.88475171  -6.25790904   0.45771224\n",
            "   -3.96070327  -7.03786304  -2.9570466    4.11196884  10.32664496\n",
            "    3.44833221   4.7376016    4.40114539   5.82708542   8.04773602\n",
            "   11.81320198   9.19828885  -4.02001067   0.67662823   1.46678385\n",
            "   13.33304047   5.46359788  -3.81371445  -1.17018222   1.02275977\n",
            "   -8.65693249 -11.13876606   2.64971415  -6.8514145    0.51882703\n",
            "   12.89392609   3.66035052   2.9823191    2.96625188  -4.17314826\n",
            "  -11.58902651   2.64353138   3.9204903    2.51857747   6.20353252]\n",
            " [ 10.53899893  -6.82126543   0.5409093   -8.26448816  -6.49016863\n",
            "    5.09901761   0.2301532    4.05052428  -6.83049373   0.7635287\n",
            "    4.81235124   8.90862512  -9.28638136   4.39454518  -6.53429473\n",
            "   -1.24416452   8.36924037  -7.25605565  -0.31493366   3.46801218\n",
            "   -3.70778693  -2.01849074  12.53138419   6.30520622  -2.32795656\n",
            "    0.08156318  -3.32783333  -3.92650911  -3.19477323   8.60304736\n",
            "    1.15250749  -0.53859893   1.3965759    0.20220281  -7.94968445\n",
            "   -5.698563     2.85557621  -5.41415634  -3.00954824   2.80066979\n",
            "   -6.78928695   0.84413629  -1.25623656   2.97998267  -7.46917961\n",
            "   -3.00359453   5.12659887  -2.54310026  -4.89951226   0.72280061\n",
            "   -0.82604704   2.30008778  -3.05435475  -1.53420992   1.15999101\n",
            "   -3.31699773  -5.25565601  -3.98437191  -2.2364406   -0.92390532\n",
            "   -0.36734377   0.66230333  -2.31289731  -5.62403627   7.50280972\n",
            "    7.57515622   4.83396583 -10.97920506   4.29392712   5.06166205\n",
            "    3.68729445  -6.12533889   7.56601375   5.29727797  -1.98157832\n",
            "    3.25443277   1.21226096  -1.70629961  -5.32003522   1.14525179\n",
            "    4.71973325  -1.87891519  -2.99513338 -10.48401311  -6.84517242\n",
            "   -4.62208625  -0.80757179   3.5518601    2.76771825  -2.90201743\n",
            "    0.55992873   5.66481508   7.34902404  -4.41768041  -9.03008563\n",
            "   -4.14197423  -5.74541598   0.86202697   1.44789859  -0.35712306]\n",
            " [ 10.53896586  -6.82095496   0.54050873  -8.26427026  -6.4899733\n",
            "    5.09891969   0.23037163   4.05039447  -6.83045799   0.76351711\n",
            "    4.8121555    8.90819701  -9.28627843   4.39462112  -6.53405481\n",
            "   -1.24403841   8.36914278  -7.25603133  -0.31494295   3.46808241\n",
            "   -3.70748397  -2.01856357  12.5312771    6.30483294  -2.32786749\n",
            "    0.08182975  -3.32789026  -3.92636765  -3.19486263   8.60289126\n",
            "    1.1525529   -0.5385029    1.39631512   0.20219673  -7.9493401\n",
            "   -5.69844345   2.85568712  -5.4141699   -3.00984626   2.80076327\n",
            "   -6.78915717   0.84401731  -1.25609246   2.98013033  -7.46923357\n",
            "   -3.00377601   5.12663416  -2.54307236  -4.89962131   0.72268247\n",
            "   -0.82624863   2.29990536  -3.05429111  -1.53404972   1.15987142\n",
            "   -3.31697459  -5.2555599   -3.98432262  -2.23631696  -0.92365973\n",
            "   -0.36733229   0.66229203  -2.31282002  -5.62399809   7.50296534\n",
            "    7.57508334   4.83376946 -10.97903575   4.29395076   5.0618113\n",
            "    3.68720398  -6.12504258   7.56605823   5.2973833   -1.98147298\n",
            "    3.25471436   1.21232066  -1.70637679  -5.31971019   1.14530277\n",
            "    4.71981115  -1.87883975  -2.99493375 -10.48372694  -6.84508247\n",
            "   -4.62206801  -0.80774764   3.55189143   2.76758109  -2.90197958\n",
            "    0.55996494   5.66489286   7.34892497  -4.41768127  -9.02999423\n",
            "   -4.14185717  -5.74526949   0.8622925    1.44801916  -0.35719581]\n",
            " [ 10.5383473   -6.81568139   0.54388586  -8.26105457  -6.48654902\n",
            "    5.09520138   0.23069278   4.053301    -6.82900357   0.76474214\n",
            "    4.81274024   8.90122573  -9.28262123   4.38876221  -6.52846012\n",
            "   -1.24772382   8.36558712  -7.25393221  -0.30997645   3.46245024\n",
            "   -3.70074296  -2.01920212  12.53209955   6.29604624  -2.32583125\n",
            "    0.07558988  -3.33037453  -3.92278944  -3.20000669   8.59858666\n",
            "    1.1533959   -0.53729564   1.39028093   0.2033916   -7.94427866\n",
            "   -5.68902002   2.86276108  -5.41374109  -3.00488356   2.79683913\n",
            "   -6.78621478   0.84170686  -1.25506141   2.98129747  -7.46694073\n",
            "   -3.00169229   5.1258942   -2.54199045  -4.90104911   0.72238951\n",
            "   -0.83379572   2.29747668  -3.05484212  -1.53502808   1.1568491\n",
            "   -3.31387894  -5.25424941  -3.98067153  -2.2340476   -0.92174951\n",
            "   -0.35875352   0.66528344  -2.30993801  -5.6229472    7.50359115\n",
            "    7.57086726   4.82810394 -10.96710376   4.29291668   5.06484236\n",
            "    3.6850362   -6.11842411   7.56400839   5.29901244  -1.9808138\n",
            "    3.2527683    1.21343356  -1.70527137  -5.31421106   1.14584901\n",
            "    4.71850513  -1.87540785  -2.99690729 -10.48043318  -6.84088828\n",
            "   -4.62129564  -0.8102366    3.54735942   2.77005886  -2.89527653\n",
            "    0.56235537   5.66579595   7.3481624   -4.41751774  -9.02891486\n",
            "   -4.14008579  -5.74163471   0.86209123   1.44747442  -0.35400326]\n",
            " [  6.59596676   8.07806396  -7.39785133  -0.87216376  -0.07911104\n",
            "   -1.44019185   7.89688044   1.51688407 -11.01589555   1.66164005\n",
            "   -0.72980996  -1.36492311  -4.59330159  -0.21858035   2.27971979\n",
            "   -2.11165285   5.01534671  -6.0196174   -2.65639139   2.54603511\n",
            "    9.02074623  -8.50392816   5.38567943  -4.22776469   1.02681302\n",
            "   -0.23552454  -0.16557941  -0.57807075  -2.90421956  -5.19806528\n",
            "    7.68036851   2.45113445 -12.25353423   2.06033636  -1.11165422\n",
            "    6.07569529  15.88061927  -9.95582691  -9.1289251   -2.00117167\n",
            "    3.10939259 -11.59441113   6.30323353   9.23544376 -12.92601806\n",
            "   -6.34620025   6.42969271  -1.49641697  -9.45773088  -1.46216427\n",
            "   -5.75729632 -10.93434174  -2.95846117   3.42807604  -0.82070451\n",
            "    2.46970687  -0.433171    -2.92258527   0.6288474    1.45085047\n",
            "    7.35337994   7.07879724  -1.11605223  -0.40622024  12.83230129\n",
            "    1.33857049  -7.2395301    1.45389475   5.37278632  10.64420202\n",
            "    1.77667666   1.50278266   9.4819944    7.55883992   1.33672469\n",
            "    8.81128659   2.68989165  -6.44529729   5.6291687    2.65117351\n",
            "    1.84816822   5.27109883  -0.99687895   1.62551674  -2.79803251\n",
            "   -1.92652929 -12.8849639    9.85826614  -0.44129134   2.46714513\n",
            "   -2.47132839  10.17823667  -0.39860324   0.26528591  -4.62150219\n",
            "    1.32685021   1.71579197   9.87561191   5.27857848   3.64772941]\n",
            " [ 11.86985323   0.61750378   7.26487338  -3.62995984  -2.1893763\n",
            "   -0.80375736   0.1741081    9.62433018  -3.75325785   1.76951119\n",
            "    5.31668306  -0.86573216  -5.50872738  -2.40148674   2.12370962\n",
            "   -7.96288194   5.60260252  -5.23670722   7.20887505  -7.57593236\n",
            "    6.48651736  -4.18950209  14.81462129  -6.1354921    2.17350109\n",
            "   -9.02264412  -7.35307561  -0.35098059 -10.48369447   2.02650692\n",
            "    2.02753634   0.73243229  -8.4166924    4.78563885  -0.19786033\n",
            "   10.45417221  16.05075575  -5.98640083   3.27931217  -4.83215172\n",
            "   -2.38482253  -1.81732423   1.05166544   3.2069879   -3.99404583\n",
            "   -1.72885694   4.57715048  -2.12848307  -8.62318179   0.37747408\n",
            "  -13.69188741  -2.06529046  -3.62968347  -4.16894679  -3.1132741\n",
            "    0.43919025  -3.80880983   0.39876327  -1.61291543   1.98026101\n",
            "   13.98733239   4.98145608   2.42325989  -3.4535579   11.52475472\n",
            "    2.832259    -1.88518035   7.26959386   4.03264101   9.34937713\n",
            "    0.58092541   4.47403502   5.52769407   7.67504033  -2.95024328\n",
            "   -0.55963143   2.87593561   2.35224112   4.05938352   2.14546758\n",
            "    1.41057194   2.93992539  -6.11739327  -7.35506554  -2.57109424\n",
            "   -2.21834514  -4.39988657  -2.974217     8.90360911   8.67865105\n",
            "    2.50855122   8.00342746   4.86510418  -5.39823482  -7.06703064\n",
            "    0.50183655  -1.03824604   2.0190128    0.10654664   3.48165675]\n",
            " [ 10.5389895   -6.82132041   0.54086008  -8.26452231  -6.4902004\n",
            "    5.09906094   0.23015333   4.05048368  -6.83051605   0.76352131\n",
            "    4.81234764   8.90869702  -9.28640926   4.3945951   -6.53435821\n",
            "   -1.24411555   8.36926096  -7.25607045  -0.31498852   3.46809287\n",
            "   -3.70786163  -2.01847458  12.53136797   6.30529765  -2.32798969\n",
            "    0.08163016  -3.32780391  -3.92653561  -3.19472007   8.60309591\n",
            "    1.15250087  -0.53860829   1.39664812   0.20216963  -7.94974129\n",
            "   -5.69868138   2.85547918  -5.41415207  -3.00959423   2.80072593\n",
            "   -6.78931944   0.84415619  -1.25625362   2.9799808   -7.46920501\n",
            "   -3.00360374   5.12660282  -2.54310337  -4.89948473   0.72280327\n",
            "   -0.82595293   2.30011998  -3.05435076  -1.53419069   1.16002247\n",
            "   -3.31702528  -5.25566672  -3.98440419  -2.23644516  -0.92392642\n",
            "   -0.3674487    0.66227151  -2.31293204  -5.62405239   7.50278039\n",
            "    7.57519147   4.83401542 -10.97933912   4.29392888   5.0616305\n",
            "    3.68731721  -6.1254167    7.56602869   5.29726053  -1.9815717\n",
            "    3.25446058   1.21224865  -1.70632895  -5.32010417   1.14524453\n",
            "    4.71975759  -1.87895059  -2.99511058 -10.48403648  -6.84520386\n",
            "   -4.62210386  -0.80754529   3.55190762   2.76767356  -2.90210243\n",
            "    0.55991454   5.66479802   7.34904244  -4.41767336  -9.03010023\n",
            "   -4.14200833  -5.74545072   0.86201831   1.44790846  -0.35715124]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KOBWN8vG1cI4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}